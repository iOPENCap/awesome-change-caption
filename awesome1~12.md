file:///c%3A/Users/luoyiyi/learngit/awesome.md {"mtime":1695369401465,"ctime":1695367934712,"size":708,"etag":"3b85snj2imq","orphaned":false,"typeId":""}
# awesome-remote-change-image
The project is currently under construction
### Papers
#### Lite Version
* [**ICIIF 2018**]  [Least Squares Twin Extreme Learning Machine for Pattern Classification](https://link.springer.com/chapter/10.1007/978-981-13-1966-2_50) *Amisha et al.*  [[paper]](https://link.springer.com/book/10.1007/978-981-13-1966-2)<br/>
* [**ScienceDirect 2001**]   [A Survey of Computer Vision-Based Human Motion Capture](https://www.sciencedirect.com/science/article/pii/S107731420090897X) *Thomas et al.*  [[paper]](https://www.sciencedirect.com/)<br/>
* [**springer 2005**]  [A Statistical Approach to Texture Classification from Single Images](https://link.springer.com/article/10.1023/B:VISI.0000046589.39864.ee) *Manik et al.*  [[paper]](https://link.springer.com/)<br/>
* [**IEEE 2000**]  [Twenty Years of Document Image Analysis in PAMI](https://ieeexplore.ieee.org/document/824820) *George Nagy.*  [[paper]](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34)<br/>
* [**IEEE 2022**]  [ChaLearn Looking at People: IsoGD and ConGD Large-Scale RGB-D Gesture Recognition](https://www.webofscience.com/wos/alldb/full-record/WOS:000798227800076) *Wan et al.*  [[paper]](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34)<br/>  
* [**IEEE 2021**]  [MVTN: Multi-View Transformation Network for 3D Shape Recognition](https://www.webofscience.com/wos/alldb/full-record/WOS:000797698900001) *Hamdi et al.*  [[paper]](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34)<br/>  
* [**IEEE 2021**]  [GLiT: Neural Architecture Search for Global and Local Image Transformer. ](https://www.webofscience.com/wos/alldb/full-record/WOS:000797698900002) *Chen et al.*  [[paper]](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34)<br/>  
* [**IEEE 2022**]  [Learning-Based Point Cloud Registration for 6D Object Pose Estimation in the Real World](https://www.webofscience.com/wos/alldb/full-record/WOS:000898293500002) *Dang et al.*  [[paper]](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34)<br/>  
* [**IEEE 2022**]  [An End-to-End Transformer Model for Crowd Localization](https://www.webofscience.com/wos/alldb/full-record/WOS:000898293500003) *Liang et al.*  [[paper]](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34)<br/>  
* [**IEEE 2022**]  [Large-Scale Pre-training for Person Re-identification with Noisy Labels.](https://www.webofscience.com/wos/alldb/full-record/WOS:000867754202072) *Fu et al.*  [[paper]](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34)<br/>  
* [**IEEE 2022**]  [Clipped Hyperbolic Classifiers Are Super-Hyperbolic Classifiers](https://www.webofscience.com/wos/alldb/full-record/WOS:000867754200002) *Guo et al.*  [[paper]](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34)<br/>
* [**IEEE 2022**]  [CO-SNE: Dimensionality Reduction and Visualization for Hyperbolic Data](https://www.webofscience.com/wos/alldb/full-record/WOS:000867754200003) *Guo et al.*  [[paper]](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34)<br/>

#### Full Version
| Paper info | Description |
|---|---|
| [Least Squares Twin Extreme Learning Machine for Pattern Classification](https://link.springer.com/chapter/10.1007/978-981-13-1966-2_50)<br/>*Rastogi, R. ; Bharti, A.*<br/>> South Asian University, New Delhi, 110021, Delhi, India<br/>> ICIIF 2018<br/>> `Extreme learning machine``Twin support vector machine``Classification``recognition`, <br/>> Cited by 2594 | <div align="center"><img src="https://raw.githubusercontent.com/iOPENCap/awesome-change-caption/img-storage/1.png" width="300"></div><br/>The paper proposes Least Squares Twin Extreme Learning Machine (LSTELM) for pattern classification . LSTELM formulation solves Extreme Learning Machine (ELM) problem in twin framework.
| [A Survey of Computer Vision-Based Human Motion Capture](https://www.sciencedirect.com/science/article/pii/S107731420090897X)<br/>*Thomas B. Moeslund and Erik Granum*<br/>> Laboratory of Computer Vision and Media Technology, Aalborg University, Niels Jernes Vej 14, Aalborg, 9220, Denmarkf1<br/>> ScienceDirect 2001<br/>> `initialization``tracking``pose estimation``Least squares`, <br/>> Cited by 6 | <div align="center"><img src="https://raw.githubusercontent.com/iOPENCap/awesome-change-caption/img-storage/2.1.png" width="300"></div><br/>The paper proposes a comprehensive survey of computer vision-based human motion capture literature from the past two decades is presented. The focus is on a general overview based on a taxonomy of system functionalities, broken down into four processes: initialization, tracking, pose estimation, and recognition.<br/> 
| [A Statistical Approach to Texture Classification from Single Images](https://link.springer.com/article/10.1023/B:VISI.0000046589.39864.ee)<br/>*Manik Varma / Andrew Zisserman*<br/>> Robotics Research Group, Department of Engineering Science, University of Oxford, Oxford, OX1 3PJ, UK<br/>> ICIIF 2018<br/>> `Extreme learning machine``Twin support vector machine``Classification``recognition`, <br/>> Cited by 2594 | <div align="center"><img src="https://raw.githubusercontent.com/iOPENCap/awesome-change-caption/img-storage/3.png" width="300"></div><br/>The paper proposes texture classification from single images obtained under unknown viewpoint and illumination. A statistical approach is developed where textures are modelled by the joint probability distribution of filter responses.
| [Twenty Years of Document Image Analysis in PAMI](https://ieeexplore.ieee.org/document/824820)<br/>*George Nagy*<br/>>  South Asian University, New Delhi, 110021, Delhi, India<br/>> IEEE 2000<br/>> ` Extreme learning machine``Twin support vector machine``Classification``Least squares`, <br/>> Cited by 6 | <div align="center"><img src="https://raw.githubusercontent.com/iOPENCap/awesome-change-caption/img-storage/4.png" width="300"></div><br/>The contributions to document image analysis of 99 papers published in the E E E Transactions on Pattern Anaiysis and Machine hteiligence (PAMI) are clustered, summarized, interpolated, interpreted, and tactfully evaluated.|
| [ChaLearn Looking at People: IsoGD and ConGD Large-Scale RGB-D Gesture Recognition](https://www.webofscience.com/wos/alldb/full-record/WOS:000798227800076)<br/>*Wan et al*<br/>>  Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China<br/>> IEEE 2022<br/>> ` Gesture recognition``Measurement``Task analysis``Training``Conferences``Computer vision``Bidirectional long short-term memory (Bi-LSTM)``gesture recognition``RGB-D`, <br/>> Cited by 7 | <div align="center"><img src="https://raw.githubusercontent.com/iOPENCap/awesome-change-caption/img-storage/5.png" width="300"></div><br/>The paper proposes it describes the creation of both benchmark datasets and analyzes the advances in large-scale gesture recognition based on these two datasets.|
| [MVTN: Multi-View Transformation Network for 3D Shape Recognition](https://www.webofscience.com/wos/alldb/full-record/WOS:000797698900001)<br/>*Hamdi et al*<br/>>  King Abdullah Univ Sci & Technol KAUST, Thuwal, Saudi Arabia<br/>> IEEE 2021<br/>> ` NEURAL-NETWORK`, <br/>> Cited by 23 | <div align="center"><img src="https://raw.githubusercontent.com/iOPENCap/awesome-change-caption/img-storage/6.png" width="300"></div><br/>The main contribution of this paper is the introduction of a Multi-View Transformation Network (MVTN) that can predict optimal viewpoints to improve 3D shape recognition performance. |
| [GLiT: Neural Architecture Search for Global and Local Image Transformer](https://www.webofscience.com/wos/alldb/full-record/WOS:000797698900002)<br/>*Chen et al*<br/>>  Univ Sydney, Sydney, NSW, Australia<br/>> IEEE 2021<br/>> ` GLiT``Image Recognition``transformer``Neural architecture Search``Local information ``Global Information``Self-attention``multi-head attention mechanism``ImageNet`, <br/>> Cited by 23 | <div align="center"><img src="https://raw.githubusercontent.com/iOPENCap/awesome-change-caption/img-storage/7.png" width="300"></div><br/>This paper introduces GLiT, the first Neural Architecture Search (NAS) method to find a better transformer architecture specifically for image recognition. |
| [Learning-Based Point Cloud Registration for 6D Object Pose Estimation in the Real World](https://www.webofscience.com/wos/alldb/full-record/WOS:000898293500002)<br/>*Dang et al*<br/>>Ecole Polytech Fed Lausanne, CVLab, Lausanne, Switzerland<br/>> IEEE 2022<br/>> ` 6D object pose estimation``Point cloud registration`, <br/>> Cited by 0 | <div align="center"><img src="https://raw.githubusercontent.com/iOPENCap/awesome-change-caption/img-storage/8.png" width="300"></div><br/>The main content of the paper is about addressing the challenges faced by learning-based 3D object registration algorithms to estimate the 6D pose of an object from point cloud data in the presence of real-world data. |
| [An End-to-End Transformer Model for Crowd Localization](https://www.webofscience.com/wos/alldb/full-record/WOS:000898293500003)<br/>*Liang et al*<br/>>Huazhong Univ Sci & Technol, Wuhan 430074, Peoples R China<br/>> IEEE 2022<br/>> `Crowd localization``Crowd counting``Transformer`, <br/>> Cited by 3 | <div align="center"><img src="https://raw.githubusercontent.com/iOPENCap/awesome-change-caption/img-storage/picture/9.png" width="300"></div><br/>The main content of this paper is the proposal of an end-to-end Crowd Localization Transformer (CLTR) model for the task of crowd localization, which aims to predict the location of each instance (head positions) in crowd scenes. |
| [Large-Scale Pre-training for Person Re-identification with Noisy Labels](https://www.webofscience.com/wos/alldb/full-record/WOS:000867754202072)<br/>*Fu et al*<br/>>Microsoft Res, Redmond, WA 98052 USA<br/>> IEEE 2022<br/>> `person re-identification, pre-training, noisy labels, prototype-based contrastive learning, label-guided contrastive learning, deep learning, computer vision`, <br/>> Cited by 2 | <div align="center"><img src="https://raw.githubusercontent.com/iOPENCap/awesome-change-caption/img-storage/picture/10.png" width="300"></div><br/>This paper proposes a framework for large-scale pre-training for person re-identification (Re-ID) with noisy labels. The framework, called PNL, consists of three learning modules: supervised Re-ID learning, prototype-based contrastive learning, and label-guided contrastive learning. |
| [Clipped Hyperbolic Classifiers Are Super-Hyperbolic Classifiers](https://www.webofscience.com/wos/alldb/full-record/WOS:000867754200002)<br/>* Guo et al*<br/>>UC Berkeley ICSI, Berkeley, CA 94720 USA<br/>> IEEE 2022<br/>> `person re-identification, pre-training, noisy labels, prototype-based contrastive learning, label-guided contrastive learning, deep learning, computer vision`, <br/>> Cited by 41 | <div align="center"><img src="https://raw.githubusercontent.com/iOPENCap/awesome-change-caption/img-storage/picture/11.png" width="300"></div><br/>This paper introduces a solution to the vanishing gradient problem in training Hyperbolic Neural Networks (HNNs), which is caused by the hybrid architecture connecting Euclidean features to a hyperbolic classifier.|
| [CO-SNE: Dimensionality Reduction and Visualization for Hyperbolic Data](https://www.webofscience.com/wos/alldb/full-record/WOS:000867754200003)<br/>* Guo et al*<br/>>UC Berkeley ICSI, Berkeley, CA 94720 USA<br/>> IEEE 2022<br/>> `CO-SNE, hyper-likelihood distribution, high-dimensional data visualization, non-Euclidean space, hierarchical structure`, <br/>> Cited by 0 | <div align="center"><img src="https://raw.githubusercontent.com/iOPENCap/awesome-change-caption/img-storage/picture/12.png" width="300"></div><br/>The main content of this article is the proposal of CO-SNE, a method for visualizing high-dimensional hyperbolic data in a low-dimensional hyperbolic space. |